2024-07-03 22:13:04,2050666342 | INFO | 25076 - Executing: config/RDT_GCN_RSGG.jsonc Run: -1
2024-07-03 22:13:04,2050666342 | INFO | 25076 - Creating the evaluation manager.......................................................
2024-07-03 22:13:04,2050666343 | INFO | 25076 - Creating the PAIRED evaluators...............................................................
2024-07-03 22:13:07,2050668889 | INFO | 25076 - Loading: REDDIT-afb11d5932fc65bf73e20d26097e9003
2024-07-03 22:13:16,2050677875 | INFO | 25076 - Created: REDDIT-afb11d5932fc65bf73e20d26097e9003
2024-07-03 22:13:40,2050702107 | INFO | 25076 - Instantiating: src.oracle.nn.gcn.DownstreamGCN
2024-07-03 22:13:40,2050702110 | INFO | 25076 - Instantiating: torch.optim.AdamW
2024-07-03 22:13:40,2050702111 | INFO | 25076 - Instantiating: torch.nn.CrossEntropyLoss
2024-07-03 22:13:43,2050704641 | INFO | 25076 - Creating: OracleTorch-1726902df6bb05e8a00dcfa663f4193f
2024-07-03 22:14:31,2050753560 | INFO | 25076 - epoch = 0 ---> loss = 0.5989	 accuracy = 0.6827
2024-07-03 22:15:02,2050784448 | INFO | 25076 - epoch = 1 ---> loss = 0.5153	 accuracy = 0.7609
2024-07-03 22:15:33,2050815477 | INFO | 25076 - epoch = 2 ---> loss = 0.5072	 accuracy = 0.7660
2024-07-03 22:16:05,2050846766 | INFO | 25076 - epoch = 3 ---> loss = 0.5047	 accuracy = 0.7678
2024-07-03 22:16:36,2050877874 | INFO | 25076 - epoch = 4 ---> loss = 0.5034	 accuracy = 0.7684
2024-07-03 22:17:07,2050908978 | INFO | 25076 - epoch = 5 ---> loss = 0.5025	 accuracy = 0.7692
2024-07-03 22:17:38,2050939974 | INFO | 25076 - epoch = 6 ---> loss = 0.5014	 accuracy = 0.7698
2024-07-03 22:18:09,2050970968 | INFO | 25076 - epoch = 7 ---> loss = 0.5009	 accuracy = 0.7701
2024-07-03 22:18:40,2051001839 | INFO | 25076 - epoch = 8 ---> loss = 0.5007	 accuracy = 0.7710
2024-07-03 22:19:11,2051032757 | INFO | 25076 - epoch = 9 ---> loss = 0.4999	 accuracy = 0.7710
2024-07-03 22:19:42,2051063719 | INFO | 25076 - epoch = 10 ---> loss = 0.4996	 accuracy = 0.7718
2024-07-03 22:20:13,2051094608 | INFO | 25076 - epoch = 11 ---> loss = 0.4992	 accuracy = 0.7713
2024-07-03 22:20:43,2051125557 | INFO | 25076 - epoch = 12 ---> loss = 0.4989	 accuracy = 0.7714
2024-07-03 22:21:14,2051156581 | INFO | 25076 - epoch = 13 ---> loss = 0.4984	 accuracy = 0.7719
2024-07-03 22:21:45,2051187419 | INFO | 25076 - epoch = 14 ---> loss = 0.4982	 accuracy = 0.7717
2024-07-03 22:22:16,2051218313 | INFO | 25076 - epoch = 15 ---> loss = 0.4978	 accuracy = 0.7727
2024-07-03 22:22:47,2051249105 | INFO | 25076 - epoch = 16 ---> loss = 0.4972	 accuracy = 0.7731
2024-07-03 22:23:18,2051279963 | INFO | 25076 - epoch = 17 ---> loss = 0.4968	 accuracy = 0.7728
2024-07-03 22:23:49,2051310787 | INFO | 25076 - epoch = 18 ---> loss = 0.4966	 accuracy = 0.7726
2024-07-03 22:24:20,2051341844 | INFO | 25076 - epoch = 19 ---> loss = 0.4962	 accuracy = 0.7728
2024-07-03 22:24:51,2051372715 | INFO | 25076 - epoch = 20 ---> loss = 0.4961	 accuracy = 0.7726
2024-07-03 22:25:21,2051403455 | INFO | 25076 - epoch = 21 ---> loss = 0.4955	 accuracy = 0.7736
2024-07-03 22:25:52,2051434318 | INFO | 25076 - epoch = 22 ---> loss = 0.4955	 accuracy = 0.7732
2024-07-03 22:26:23,2051465328 | INFO | 25076 - epoch = 23 ---> loss = 0.4951	 accuracy = 0.7734
2024-07-03 22:26:54,2051496182 | INFO | 25076 - epoch = 24 ---> loss = 0.4952	 accuracy = 0.7734
2024-07-03 22:27:27,2051528645 | INFO | 25076 - epoch = 25 ---> loss = 0.4949	 accuracy = 0.7738
2024-07-03 22:27:59,2051560934 | INFO | 25076 - epoch = 26 ---> loss = 0.4944	 accuracy = 0.7742
2024-07-03 22:28:32,2051594148 | INFO | 25076 - epoch = 27 ---> loss = 0.4940	 accuracy = 0.7742
2024-07-03 22:29:04,2051625827 | INFO | 25076 - epoch = 28 ---> loss = 0.4943	 accuracy = 0.7740
2024-07-03 22:29:35,2051657583 | INFO | 25076 - epoch = 29 ---> loss = 0.4935	 accuracy = 0.7743
2024-07-03 22:30:07,2051689100 | INFO | 25076 - epoch = 30 ---> loss = 0.4935	 accuracy = 0.7748
2024-07-03 22:30:38,2051720518 | INFO | 25076 - epoch = 31 ---> loss = 0.4934	 accuracy = 0.7741
2024-07-03 22:31:10,2051751918 | INFO | 25076 - epoch = 32 ---> loss = 0.4930	 accuracy = 0.7749
2024-07-03 22:31:41,2051783464 | INFO | 25076 - epoch = 33 ---> loss = 0.4929	 accuracy = 0.7741
2024-07-03 22:32:13,2051814851 | INFO | 25076 - epoch = 34 ---> loss = 0.4928	 accuracy = 0.7744
2024-07-03 22:32:44,2051846226 | INFO | 25076 - epoch = 35 ---> loss = 0.4927	 accuracy = 0.7747
2024-07-03 22:33:16,2051877646 | INFO | 25076 - epoch = 36 ---> loss = 0.4925	 accuracy = 0.7745
2024-07-03 22:33:47,2051909142 | INFO | 25076 - epoch = 37 ---> loss = 0.4926	 accuracy = 0.7748
2024-07-03 22:34:19,2051940630 | INFO | 25076 - epoch = 38 ---> loss = 0.4921	 accuracy = 0.7750
2024-07-03 22:34:50,2051972043 | INFO | 25076 - epoch = 39 ---> loss = 0.4922	 accuracy = 0.7745
2024-07-03 22:35:21,2052003322 | INFO | 25076 - epoch = 40 ---> loss = 0.4921	 accuracy = 0.7749
2024-07-03 22:35:53,2052034714 | INFO | 25076 - epoch = 41 ---> loss = 0.4919	 accuracy = 0.7754
2024-07-03 22:36:24,2052066087 | INFO | 25076 - epoch = 42 ---> loss = 0.4916	 accuracy = 0.7753
2024-07-03 22:36:56,2052097674 | INFO | 25076 - epoch = 43 ---> loss = 0.4916	 accuracy = 0.7751
2024-07-03 22:37:27,2052129182 | INFO | 25076 - epoch = 44 ---> loss = 0.4913	 accuracy = 0.7754
2024-07-03 22:37:58,2052160533 | INFO | 25076 - epoch = 45 ---> loss = 0.4912	 accuracy = 0.7750
2024-07-03 22:38:30,2052192076 | INFO | 25076 - epoch = 46 ---> loss = 0.4913	 accuracy = 0.7752
2024-07-03 22:39:01,2052223361 | INFO | 25076 - epoch = 47 ---> loss = 0.4913	 accuracy = 0.7749
2024-07-03 22:39:33,2052254617 | INFO | 25076 - epoch = 48 ---> loss = 0.4911	 accuracy = 0.7753
2024-07-03 22:40:04,2052286156 | INFO | 25076 - epoch = 49 ---> loss = 0.4913	 accuracy = 0.7753
2024-07-03 22:40:35,2052317171 | INFO | 25076 - epoch = 50 ---> loss = 0.4908	 accuracy = 0.7756
2024-07-03 22:41:06,2052348058 | INFO | 25076 - epoch = 51 ---> loss = 0.4906	 accuracy = 0.7756
2024-07-03 22:41:37,2052378654 | INFO | 25076 - epoch = 52 ---> loss = 0.4905	 accuracy = 0.7755
2024-07-03 22:42:07,2052409367 | INFO | 25076 - epoch = 53 ---> loss = 0.4903	 accuracy = 0.7755
2024-07-03 22:42:38,2052440008 | INFO | 25076 - epoch = 54 ---> loss = 0.4905	 accuracy = 0.7757
2024-07-03 22:43:09,2052470840 | INFO | 25076 - epoch = 55 ---> loss = 0.4901	 accuracy = 0.7755
2024-07-03 22:43:41,2052503281 | INFO | 25076 - epoch = 56 ---> loss = 0.4902	 accuracy = 0.7763
2024-07-03 22:44:13,2052535068 | INFO | 25076 - epoch = 57 ---> loss = 0.4900	 accuracy = 0.7749
2024-07-03 22:44:44,2052566138 | INFO | 25076 - epoch = 58 ---> loss = 0.4899	 accuracy = 0.7759
2024-07-03 22:45:15,2052597075 | INFO | 25076 - epoch = 59 ---> loss = 0.4899	 accuracy = 0.7757
2024-07-03 22:45:46,2052628243 | INFO | 25076 - epoch = 60 ---> loss = 0.4899	 accuracy = 0.7754
2024-07-03 22:46:17,2052659429 | INFO | 25076 - epoch = 61 ---> loss = 0.4896	 accuracy = 0.7765
2024-07-03 22:46:48,2052690086 | INFO | 25076 - epoch = 62 ---> loss = 0.4899	 accuracy = 0.7757
2024-07-03 22:47:19,2052720791 | INFO | 25076 - epoch = 63 ---> loss = 0.4895	 accuracy = 0.7761
2024-07-03 22:47:49,2052751515 | INFO | 25076 - epoch = 64 ---> loss = 0.4895	 accuracy = 0.7758
2024-07-03 22:48:20,2052782280 | INFO | 25076 - epoch = 65 ---> loss = 0.4894	 accuracy = 0.7760
2024-07-03 22:48:51,2052813010 | INFO | 25076 - epoch = 66 ---> loss = 0.4892	 accuracy = 0.7763
2024-07-03 22:49:22,2052843826 | INFO | 25076 - epoch = 67 ---> loss = 0.4891	 accuracy = 0.7762
2024-07-03 22:49:53,2052875175 | INFO | 25076 - epoch = 68 ---> loss = 0.4892	 accuracy = 0.7764
2024-07-03 22:50:24,2052905843 | INFO | 25076 - epoch = 69 ---> loss = 0.4892	 accuracy = 0.7761
2024-07-03 22:50:55,2052936877 | INFO | 25076 - epoch = 70 ---> loss = 0.4890	 accuracy = 0.7760
2024-07-03 22:51:26,2052968097 | INFO | 25076 - epoch = 71 ---> loss = 0.4889	 accuracy = 0.7764
2024-07-03 22:51:57,2052998860 | INFO | 25076 - epoch = 72 ---> loss = 0.4888	 accuracy = 0.7769
2024-07-03 22:52:28,2053029632 | INFO | 25076 - epoch = 73 ---> loss = 0.4889	 accuracy = 0.7765
2024-07-03 22:52:58,2053060353 | INFO | 25076 - epoch = 74 ---> loss = 0.4888	 accuracy = 0.7766
2024-07-03 22:53:29,2053091190 | INFO | 25076 - epoch = 75 ---> loss = 0.4886	 accuracy = 0.7763
2024-07-03 22:54:00,2053122257 | INFO | 25076 - epoch = 76 ---> loss = 0.4887	 accuracy = 0.7764
2024-07-03 22:54:32,2053154034 | INFO | 25076 - epoch = 77 ---> loss = 0.4886	 accuracy = 0.7764
2024-07-03 22:55:03,2053184770 | INFO | 25076 - epoch = 78 ---> loss = 0.4886	 accuracy = 0.7767
2024-07-03 22:55:33,2053215429 | INFO | 25076 - epoch = 79 ---> loss = 0.4889	 accuracy = 0.7762
2024-07-03 22:56:04,2053246290 | INFO | 25076 - epoch = 80 ---> loss = 0.4883	 accuracy = 0.7768
2024-07-03 22:56:35,2053277035 | INFO | 25076 - epoch = 81 ---> loss = 0.4883	 accuracy = 0.7765
2024-07-03 22:57:06,2053308586 | INFO | 25076 - epoch = 82 ---> loss = 0.4883	 accuracy = 0.7763
2024-07-03 22:57:37,2053339235 | INFO | 25076 - epoch = 83 ---> loss = 0.4882	 accuracy = 0.7767
2024-07-03 22:58:08,2053369892 | INFO | 25076 - epoch = 84 ---> loss = 0.4880	 accuracy = 0.7765
2024-07-03 22:58:39,2053400650 | INFO | 25076 - epoch = 85 ---> loss = 0.4882	 accuracy = 0.7765
2024-07-03 22:59:11,2053433123 | INFO | 25076 - epoch = 86 ---> loss = 0.4881	 accuracy = 0.7766
2024-07-03 22:59:42,2053463898 | INFO | 25076 - epoch = 87 ---> loss = 0.4881	 accuracy = 0.7764
2024-07-03 23:00:12,2053494592 | INFO | 25076 - epoch = 88 ---> loss = 0.4881	 accuracy = 0.7765
2024-07-03 23:00:43,2053525512 | INFO | 25076 - epoch = 89 ---> loss = 0.4878	 accuracy = 0.7772
2024-07-03 23:01:16,2053557619 | INFO | 25076 - epoch = 90 ---> loss = 0.4879	 accuracy = 0.7765
2024-07-03 23:01:46,2053588420 | INFO | 25076 - epoch = 91 ---> loss = 0.4878	 accuracy = 0.7769
2024-07-03 23:02:17,2053619118 | INFO | 25076 - epoch = 92 ---> loss = 0.4876	 accuracy = 0.7770
2024-07-03 23:02:48,2053649807 | INFO | 25076 - epoch = 93 ---> loss = 0.4875	 accuracy = 0.7772
2024-07-03 23:03:18,2053680560 | INFO | 25076 - epoch = 94 ---> loss = 0.4875	 accuracy = 0.7763
2024-07-03 23:03:49,2053711308 | INFO | 25076 - epoch = 95 ---> loss = 0.4874	 accuracy = 0.7772
2024-07-03 23:04:20,2053742160 | INFO | 25076 - epoch = 96 ---> loss = 0.4875	 accuracy = 0.7770
2024-07-03 23:04:51,2053772947 | INFO | 25076 - epoch = 97 ---> loss = 0.4874	 accuracy = 0.7772
2024-07-03 23:05:22,2053803815 | INFO | 25076 - epoch = 98 ---> loss = 0.4875	 accuracy = 0.7767
2024-07-03 23:05:53,2053834688 | INFO | 25076 - epoch = 99 ---> loss = 0.4874	 accuracy = 0.7768
2024-07-03 23:06:33,2053875567 | INFO | 25076 - Test accuracy = 0.7770
2024-07-03 23:06:33,2053875589 | INFO | 25076 - OracleTorch trained on cpu in: 3170.9471797943115 secs
2024-07-03 23:06:34,2053876429 | INFO | 25076 - Saved: OracleTorch-1726902df6bb05e8a00dcfa663f4193f
2024-07-03 23:06:34,2053876434 | INFO | 25076 - Created: OracleTorch-1726902df6bb05e8a00dcfa663f4193f
2024-07-03 23:06:34,2053876441 | INFO | 25076 - Instantiating: src.explainer.generative.gans.graph.model.GAN
2024-07-03 23:06:34,2053876537 | INFO | 25076 - Instantiating: src.explainer.generative.gans.graph.res_gen.ResGenerator
2024-07-03 23:06:34,2053876539 | INFO | 25076 - Instantiating: torch.optim.SGD
2024-07-03 23:06:34,2053876539 | INFO | 25076 - Instantiating: src.explainer.generative.gans.graph.discriminators.SimpleDiscriminator
2024-07-03 23:06:34,2053876540 | INFO | 25076 - Instantiating: torch.optim.SGD
2024-07-03 23:06:34,2053876540 | INFO | 25076 - Instantiating: torch.nn.BCELoss
2024-07-03 23:06:37,2053879092 | INFO | 25076 - Creating: GAN-c5e804f1db461cd04a511a78a5f71db6
2024-07-03 23:07:10,2053912455 | INFO | 25076 - Epoch 0	 Loss_D =  0.6013	 Loss_G =  0.7721
2024-07-03 23:07:10,2053912470 | INFO | 25076 - Epoch 1	 Loss_D =  0.5873	 Loss_G =  0.6641
2024-07-03 23:07:10,2053912484 | INFO | 25076 - Epoch 2	 Loss_D =  0.6157	 Loss_G =  0.7040
2024-07-03 23:07:10,2053912498 | INFO | 25076 - Epoch 3	 Loss_D =  0.8192	 Loss_G =  2.0796
2024-07-03 23:07:10,2053912512 | INFO | 25076 - Epoch 4	 Loss_D =  0.6662	 Loss_G =  1.1801
2024-07-03 23:07:10,2053912527 | INFO | 25076 - Epoch 5	 Loss_D =  0.6518	 Loss_G =  1.1023
2024-07-03 23:07:10,2053912541 | INFO | 25076 - Epoch 6	 Loss_D =  0.7429	 Loss_G =  2.7206
2024-07-03 23:07:10,2053912556 | INFO | 25076 - Epoch 7	 Loss_D =  0.6392	 Loss_G =  3.1720
2024-07-03 23:07:10,2053912569 | INFO | 25076 - Epoch 8	 Loss_D =  1.2965	 Loss_G =  0.7303
2024-07-03 23:07:10,2053912583 | INFO | 25076 - Epoch 9	 Loss_D =  0.5376	 Loss_G =  0.6761
2024-07-03 23:07:10,2053912597 | INFO | 25076 - Epoch 10	 Loss_D =  0.7640	 Loss_G =  0.6666
2024-07-03 23:07:11,2053912610 | INFO | 25076 - Epoch 11	 Loss_D =  0.7265	 Loss_G =  1.2351
2024-07-03 23:07:11,2053912623 | INFO | 25076 - Epoch 12	 Loss_D =  0.7618	 Loss_G =  1.2639
2024-07-03 23:07:11,2053912636 | INFO | 25076 - Epoch 13	 Loss_D =  0.4742	 Loss_G =  0.6225
2024-07-03 23:07:11,2053912649 | INFO | 25076 - Epoch 14	 Loss_D =  0.6383	 Loss_G =  2.1481
2024-07-03 23:07:11,2053912663 | INFO | 25076 - Epoch 15	 Loss_D =  0.6195	 Loss_G =  0.6873
2024-07-03 23:07:11,2053912675 | INFO | 25076 - Epoch 16	 Loss_D =  0.6245	 Loss_G =  0.6975
2024-07-03 23:07:11,2053912689 | INFO | 25076 - Epoch 17	 Loss_D =  0.8374	 Loss_G =  0.6141
2024-07-03 23:07:11,2053912701 | INFO | 25076 - Epoch 18	 Loss_D =  0.5069	 Loss_G =  0.7556
2024-07-03 23:07:11,2053912714 | INFO | 25076 - Epoch 19	 Loss_D =  0.6893	 Loss_G =  0.7383
2024-07-03 23:07:11,2053912727 | INFO | 25076 - Epoch 20	 Loss_D =  0.9783	 Loss_G =  0.6357
2024-07-03 23:07:11,2053912740 | INFO | 25076 - Epoch 21	 Loss_D =  0.6905	 Loss_G =  0.6554
2024-07-03 23:07:11,2053912754 | INFO | 25076 - Epoch 22	 Loss_D =  0.7288	 Loss_G =  1.6925
2024-07-03 23:07:11,2053912768 | INFO | 25076 - Epoch 23	 Loss_D =  0.6318	 Loss_G =  0.9407
2024-07-03 23:07:11,2053912781 | INFO | 25076 - Epoch 24	 Loss_D =  0.7366	 Loss_G =  0.5924
2024-07-03 23:07:11,2053912795 | INFO | 25076 - Epoch 25	 Loss_D =  0.9002	 Loss_G =  0.4909
2024-07-03 23:07:11,2053912809 | INFO | 25076 - Epoch 26	 Loss_D =  0.7095	 Loss_G =  0.8334
2024-07-03 23:07:11,2053912823 | INFO | 25076 - Epoch 27	 Loss_D =  0.6309	 Loss_G =  3.4633
2024-07-03 23:07:11,2053912838 | INFO | 25076 - Epoch 28	 Loss_D =  0.6404	 Loss_G =  1.0152
2024-07-03 23:07:11,2053912850 | INFO | 25076 - Epoch 29	 Loss_D =  0.6679	 Loss_G =  0.4119
2024-07-03 23:07:11,2053912863 | INFO | 25076 - Epoch 30	 Loss_D =  0.6184	 Loss_G =  1.5813
2024-07-03 23:07:11,2053912877 | INFO | 25076 - Epoch 31	 Loss_D =  0.4694	 Loss_G =  0.4577
2024-07-03 23:07:11,2053912890 | INFO | 25076 - Epoch 32	 Loss_D =  0.4378	 Loss_G =  0.6863
2024-07-03 23:07:11,2053912904 | INFO | 25076 - Epoch 33	 Loss_D =  0.5827	 Loss_G =  1.5905
2024-07-03 23:07:11,2053912916 | INFO | 25076 - Epoch 34	 Loss_D =  0.5284	 Loss_G =  1.7474
2024-07-03 23:07:11,2053912930 | INFO | 25076 - Epoch 35	 Loss_D =  0.7314	 Loss_G =  0.6271
2024-07-03 23:07:11,2053912945 | INFO | 25076 - Epoch 36	 Loss_D =  1.2254	 Loss_G =  1.1809
2024-07-03 23:07:11,2053912958 | INFO | 25076 - Epoch 37	 Loss_D =  0.6897	 Loss_G =  0.7392
2024-07-03 23:07:11,2053912970 | INFO | 25076 - Epoch 38	 Loss_D =  0.6541	 Loss_G =  0.6140
2024-07-03 23:07:11,2053912984 | INFO | 25076 - Epoch 39	 Loss_D =  0.6170	 Loss_G =  3.5354
2024-07-03 23:07:11,2053912998 | INFO | 25076 - Epoch 40	 Loss_D =  0.3570	 Loss_G =  0.6373
2024-07-03 23:07:11,2053913010 | INFO | 25076 - Epoch 41	 Loss_D =  0.7620	 Loss_G =  1.7760
2024-07-03 23:07:11,2053913024 | INFO | 25076 - Epoch 42	 Loss_D =  0.4288	 Loss_G =  0.5934
2024-07-03 23:07:11,2053913037 | INFO | 25076 - Epoch 43	 Loss_D =  0.7295	 Loss_G =  0.6258
2024-07-03 23:07:11,2053913050 | INFO | 25076 - Epoch 44	 Loss_D =  0.6132	 Loss_G =  0.5955
2024-07-03 23:07:11,2053913064 | INFO | 25076 - Epoch 45	 Loss_D =  0.6387	 Loss_G =  1.1147
2024-07-03 23:07:11,2053913077 | INFO | 25076 - Epoch 46	 Loss_D =  0.3081	 Loss_G =  0.4014
2024-07-03 23:07:11,2053913092 | INFO | 25076 - Epoch 47	 Loss_D =  1.2066	 Loss_G =  0.2978
2024-07-03 23:07:11,2053913105 | INFO | 25076 - Epoch 48	 Loss_D =  0.7855	 Loss_G =  0.3823
2024-07-03 23:07:11,2053913118 | INFO | 25076 - Epoch 49	 Loss_D =  0.6461	 Loss_G =  0.4605
2024-07-03 23:07:11,2053913133 | INFO | 25076 - Epoch 50	 Loss_D =  0.3300	 Loss_G =  0.6193
2024-07-03 23:07:11,2053913146 | INFO | 25076 - Epoch 51	 Loss_D =  0.3870	 Loss_G =  0.6276
2024-07-03 23:07:11,2053913160 | INFO | 25076 - Epoch 52	 Loss_D =  0.3690	 Loss_G =  0.5256
2024-07-03 23:07:11,2053913172 | INFO | 25076 - Epoch 53	 Loss_D =  0.6212	 Loss_G =  2.2749
2024-07-03 23:07:11,2053913185 | INFO | 25076 - Epoch 54	 Loss_D =  0.8308	 Loss_G =  4.7139
2024-07-03 23:07:11,2053913198 | INFO | 25076 - Epoch 55	 Loss_D =  0.4802	 Loss_G =  0.5838
2024-07-03 23:07:11,2053913211 | INFO | 25076 - Epoch 56	 Loss_D =  0.8875	 Loss_G =  0.7069
2024-07-03 23:07:11,2053913224 | INFO | 25076 - Epoch 57	 Loss_D =  0.3113	 Loss_G =  3.4887
2024-07-03 23:07:11,2053913238 | INFO | 25076 - Epoch 58	 Loss_D =  0.6529	 Loss_G =  0.6883
2024-07-03 23:07:11,2053913250 | INFO | 25076 - Epoch 59	 Loss_D =  0.4372	 Loss_G =  0.6933
2024-07-03 23:07:11,2053913264 | INFO | 25076 - Epoch 60	 Loss_D =  4.0447	 Loss_G =  0.2645
2024-07-03 23:07:11,2053913278 | INFO | 25076 - Epoch 61	 Loss_D =  0.9651	 Loss_G =  0.6406
2024-07-03 23:07:11,2053913290 | INFO | 25076 - Epoch 62	 Loss_D =  0.7736	 Loss_G =  1.7039
2024-07-03 23:07:11,2053913304 | INFO | 25076 - Epoch 63	 Loss_D =  0.3210	 Loss_G =  2.2991
2024-07-03 23:07:11,2053913317 | INFO | 25076 - Epoch 64	 Loss_D =  0.8776	 Loss_G =  0.8309
2024-07-03 23:07:11,2053913330 | INFO | 25076 - Epoch 65	 Loss_D =  0.3736	 Loss_G =  1.1782
2024-07-03 23:07:11,2053913344 | INFO | 25076 - Epoch 66	 Loss_D =  0.6343	 Loss_G =  0.6624
2024-07-03 23:07:11,2053913358 | INFO | 25076 - Epoch 67	 Loss_D =  0.5545	 Loss_G =  2.8663
2024-07-03 23:07:11,2053913371 | INFO | 25076 - Epoch 68	 Loss_D =  0.7728	 Loss_G =  0.5678
2024-07-03 23:07:11,2053913384 | INFO | 25076 - Epoch 69	 Loss_D =  0.4328	 Loss_G =  1.3031
2024-07-03 23:07:11,2053913398 | INFO | 25076 - Epoch 70	 Loss_D =  0.3779	 Loss_G =  0.6934
2024-07-03 23:07:11,2053913412 | INFO | 25076 - Epoch 71	 Loss_D =  0.8706	 Loss_G =  0.7023
2024-07-03 23:07:11,2053913425 | INFO | 25076 - Epoch 72	 Loss_D =  0.7700	 Loss_G =  1.7227
2024-07-03 23:07:11,2053913438 | INFO | 25076 - Epoch 73	 Loss_D =  0.4173	 Loss_G =  4.5472
2024-07-03 23:07:11,2053913450 | INFO | 25076 - Epoch 74	 Loss_D =  0.5934	 Loss_G =  0.5985
2024-07-03 23:07:11,2053913465 | INFO | 25076 - Epoch 75	 Loss_D =  0.7853	 Loss_G =  0.7727
2024-07-03 23:07:11,2053913478 | INFO | 25076 - Epoch 76	 Loss_D =  0.2567	 Loss_G =  3.7207
2024-07-03 23:07:11,2053913492 | INFO | 25076 - Epoch 77	 Loss_D =  0.5595	 Loss_G =  6.4816
2024-07-03 23:07:11,2053913507 | INFO | 25076 - Epoch 78	 Loss_D =  0.7633	 Loss_G =  2.8174
2024-07-03 23:07:11,2053913520 | INFO | 25076 - Epoch 79	 Loss_D =  0.6056	 Loss_G =  3.9308
2024-07-03 23:07:11,2053913534 | INFO | 25076 - Epoch 80	 Loss_D =  0.8306	 Loss_G =  0.6608
2024-07-03 23:07:11,2053913547 | INFO | 25076 - Epoch 81	 Loss_D =  0.3177	 Loss_G =  0.6966
2024-07-03 23:07:11,2053913560 | INFO | 25076 - Epoch 82	 Loss_D =  0.6818	 Loss_G =  0.4783
2024-07-03 23:07:11,2053913574 | INFO | 25076 - Epoch 83	 Loss_D =  0.6587	 Loss_G =  3.8208
2024-07-03 23:07:11,2053913587 | INFO | 25076 - Epoch 84	 Loss_D =  0.7670	 Loss_G =  0.4957
2024-07-03 23:07:11,2053913600 | INFO | 25076 - Epoch 85	 Loss_D =  0.8906	 Loss_G =  1.4008
2024-07-03 23:07:12,2053913624 | INFO | 25076 - Epoch 86	 Loss_D =  0.4182	 Loss_G =  2.4412
2024-07-03 23:07:12,2053913643 | INFO | 25076 - Epoch 87	 Loss_D =  1.1314	 Loss_G =  0.6109
2024-07-03 23:07:12,2053913660 | INFO | 25076 - Epoch 88	 Loss_D =  0.6185	 Loss_G =  0.5062
2024-07-03 23:07:12,2053913674 | INFO | 25076 - Epoch 89	 Loss_D =  0.7493	 Loss_G =  2.3168
2024-07-03 23:07:12,2053913688 | INFO | 25076 - Epoch 90	 Loss_D =  0.4374	 Loss_G =  0.6257
2024-07-03 23:07:12,2053913702 | INFO | 25076 - Epoch 91	 Loss_D =  0.7426	 Loss_G =  1.8708
2024-07-03 23:07:12,2053913716 | INFO | 25076 - Epoch 92	 Loss_D =  0.6781	 Loss_G =  2.2028
2024-07-03 23:07:12,2053913731 | INFO | 25076 - Epoch 93	 Loss_D =  0.2048	 Loss_G =  0.4419
2024-07-03 23:07:12,2053913745 | INFO | 25076 - Epoch 94	 Loss_D =  0.4844	 Loss_G =  3.3858
2024-07-03 23:07:12,2053913760 | INFO | 25076 - Epoch 95	 Loss_D =  0.8094	 Loss_G =  0.6014
2024-07-03 23:07:12,2053913774 | INFO | 25076 - Epoch 96	 Loss_D =  0.4700	 Loss_G =  2.5902
2024-07-03 23:07:12,2053913788 | INFO | 25076 - Epoch 97	 Loss_D =  0.2322	 Loss_G =  2.2920
2024-07-03 23:07:12,2053913802 | INFO | 25076 - Epoch 98	 Loss_D =  0.7021	 Loss_G =  0.6106
2024-07-03 23:07:12,2053913815 | INFO | 25076 - Epoch 99	 Loss_D =  0.1663	 Loss_G =  0.6229
2024-07-03 23:07:12,2053914392 | INFO | 25076 - GAN trained on cpu in: 35.30091571807861 secs
2024-07-03 23:07:13,2053915246 | INFO | 25076 - Saved: GAN-c5e804f1db461cd04a511a78a5f71db6
2024-07-03 23:07:13,2053915250 | INFO | 25076 - Instantiating: src.explainer.generative.gans.graph.model.GAN
2024-07-03 23:07:13,2053915252 | INFO | 25076 - Instantiating: src.explainer.generative.gans.graph.res_gen.ResGenerator
2024-07-03 23:07:13,2053915253 | INFO | 25076 - Instantiating: torch.optim.SGD
2024-07-03 23:07:13,2053915253 | INFO | 25076 - Instantiating: src.explainer.generative.gans.graph.discriminators.SimpleDiscriminator
2024-07-03 23:07:13,2053915255 | INFO | 25076 - Instantiating: torch.optim.SGD
2024-07-03 23:07:13,2053915255 | INFO | 25076 - Instantiating: torch.nn.BCELoss
2024-07-03 23:07:16,2053917788 | INFO | 25076 - Creating: GAN-2720a4c91b0a5f8cfef5a5a97fca8c4a
2024-07-03 23:07:51,2053953326 | INFO | 25076 - Epoch 0	 Loss_D =  0.6808	 Loss_G =  0.6678
2024-07-03 23:07:51,2053953341 | INFO | 25076 - Epoch 1	 Loss_D =  0.6883	 Loss_G =  0.6660
2024-07-03 23:07:51,2053953357 | INFO | 25076 - Epoch 2	 Loss_D =  0.7166	 Loss_G =  0.6629
2024-07-03 23:07:51,2053953374 | INFO | 25076 - Epoch 3	 Loss_D =  0.7190	 Loss_G =  0.6705
2024-07-03 23:07:51,2053953389 | INFO | 25076 - Epoch 4	 Loss_D =  0.7052	 Loss_G =  0.6837
2024-07-03 23:07:51,2053953405 | INFO | 25076 - Epoch 5	 Loss_D =  0.6946	 Loss_G =  0.6678
2024-07-03 23:07:51,2053953419 | INFO | 25076 - Epoch 6	 Loss_D =  0.7023	 Loss_G =  0.6067
2024-07-03 23:07:51,2053953434 | INFO | 25076 - Epoch 7	 Loss_D =  0.7312	 Loss_G =  0.6597
2024-07-03 23:07:51,2053953449 | INFO | 25076 - Epoch 8	 Loss_D =  0.7056	 Loss_G =  0.6860
2024-07-03 23:07:51,2053953463 | INFO | 25076 - Epoch 9	 Loss_D =  0.6804	 Loss_G =  0.6920
2024-07-03 23:07:51,2053953479 | INFO | 25076 - Epoch 10	 Loss_D =  0.7049	 Loss_G =  0.6539
2024-07-03 23:07:51,2053953495 | INFO | 25076 - Epoch 11	 Loss_D =  0.6841	 Loss_G =  0.6982
2024-07-03 23:07:51,2053953510 | INFO | 25076 - Epoch 12	 Loss_D =  0.6765	 Loss_G =  0.6939
2024-07-03 23:07:51,2053953525 | INFO | 25076 - Epoch 13	 Loss_D =  0.6720	 Loss_G =  0.7258
2024-07-03 23:07:51,2053953539 | INFO | 25076 - Epoch 14	 Loss_D =  0.6949	 Loss_G =  0.7207
2024-07-03 23:07:51,2053953554 | INFO | 25076 - Epoch 15	 Loss_D =  0.6830	 Loss_G =  0.7176
2024-07-03 23:07:51,2053953569 | INFO | 25076 - Epoch 16	 Loss_D =  0.6883	 Loss_G =  0.7226
2024-07-03 23:07:51,2053953584 | INFO | 25076 - Epoch 17	 Loss_D =  0.6816	 Loss_G =  0.7429
2024-07-03 23:07:51,2053953599 | INFO | 25076 - Epoch 18	 Loss_D =  0.6880	 Loss_G =  0.7284
2024-07-03 23:07:52,2053953614 | INFO | 25076 - Epoch 19	 Loss_D =  0.7583	 Loss_G =  0.6952
2024-07-03 23:07:52,2053953628 | INFO | 25076 - Epoch 20	 Loss_D =  0.6657	 Loss_G =  0.7196
2024-07-03 23:07:52,2053953642 | INFO | 25076 - Epoch 21	 Loss_D =  0.6539	 Loss_G =  0.7091
2024-07-03 23:07:52,2053953656 | INFO | 25076 - Epoch 22	 Loss_D =  0.6104	 Loss_G =  0.7526
2024-07-03 23:07:52,2053953672 | INFO | 25076 - Epoch 23	 Loss_D =  0.7004	 Loss_G =  0.6865
2024-07-03 23:07:52,2053953687 | INFO | 25076 - Epoch 24	 Loss_D =  0.7420	 Loss_G =  0.6657
2024-07-03 23:07:52,2053953701 | INFO | 25076 - Epoch 25	 Loss_D =  0.6940	 Loss_G =  0.6783
2024-07-03 23:07:52,2053953715 | INFO | 25076 - Epoch 26	 Loss_D =  0.6747	 Loss_G =  0.6966
2024-07-03 23:07:52,2053953730 | INFO | 25076 - Epoch 27	 Loss_D =  0.7115	 Loss_G =  0.6823
2024-07-03 23:07:52,2053953745 | INFO | 25076 - Epoch 28	 Loss_D =  0.7407	 Loss_G =  0.6700
2024-07-03 23:07:52,2053953760 | INFO | 25076 - Epoch 29	 Loss_D =  0.7033	 Loss_G =  0.7005
2024-07-03 23:07:52,2053953774 | INFO | 25076 - Epoch 30	 Loss_D =  0.7375	 Loss_G =  0.7079
2024-07-03 23:07:52,2053953787 | INFO | 25076 - Epoch 31	 Loss_D =  0.7007	 Loss_G =  0.6805
2024-07-03 23:07:52,2053953802 | INFO | 25076 - Epoch 32	 Loss_D =  0.6708	 Loss_G =  0.7073
2024-07-03 23:07:52,2053953816 | INFO | 25076 - Epoch 33	 Loss_D =  0.6585	 Loss_G =  0.7269
2024-07-03 23:07:52,2053953829 | INFO | 25076 - Epoch 34	 Loss_D =  0.6545	 Loss_G =  0.7382
2024-07-03 23:07:52,2053953845 | INFO | 25076 - Epoch 35	 Loss_D =  0.6453	 Loss_G =  0.7504
2024-07-03 23:07:52,2053953859 | INFO | 25076 - Epoch 36	 Loss_D =  0.7478	 Loss_G =  0.7448
2024-07-03 23:07:52,2053953874 | INFO | 25076 - Epoch 37	 Loss_D =  0.7179	 Loss_G =  0.7490
2024-07-03 23:07:52,2053953889 | INFO | 25076 - Epoch 38	 Loss_D =  0.6433	 Loss_G =  0.8558
2024-07-03 23:07:52,2053953903 | INFO | 25076 - Epoch 39	 Loss_D =  0.6705	 Loss_G =  0.7127
2024-07-03 23:07:52,2053953917 | INFO | 25076 - Epoch 40	 Loss_D =  0.6688	 Loss_G =  0.7136
2024-07-03 23:07:52,2053953933 | INFO | 25076 - Epoch 41	 Loss_D =  0.6824	 Loss_G =  0.7265
2024-07-03 23:07:52,2053953947 | INFO | 25076 - Epoch 42	 Loss_D =  0.6448	 Loss_G =  0.7372
2024-07-03 23:07:52,2053953961 | INFO | 25076 - Epoch 43	 Loss_D =  0.5810	 Loss_G =  0.7480
2024-07-03 23:07:52,2053953976 | INFO | 25076 - Epoch 44	 Loss_D =  0.8530	 Loss_G =  0.7239
2024-07-03 23:07:52,2053953990 | INFO | 25076 - Epoch 45	 Loss_D =  0.6833	 Loss_G =  0.7048
2024-07-03 23:07:52,2053954005 | INFO | 25076 - Epoch 46	 Loss_D =  0.6686	 Loss_G =  0.7046
2024-07-03 23:07:52,2053954019 | INFO | 25076 - Epoch 47	 Loss_D =  0.6904	 Loss_G =  0.7292
2024-07-03 23:07:52,2053954034 | INFO | 25076 - Epoch 48	 Loss_D =  0.6934	 Loss_G =  0.7072
2024-07-03 23:07:52,2053954047 | INFO | 25076 - Epoch 49	 Loss_D =  0.6971	 Loss_G =  0.6607
2024-07-03 23:07:52,2053954061 | INFO | 25076 - Epoch 50	 Loss_D =  0.6990	 Loss_G =  0.7011
2024-07-03 23:07:52,2053954076 | INFO | 25076 - Epoch 51	 Loss_D =  0.6314	 Loss_G =  0.6832
2024-07-03 23:07:52,2053954091 | INFO | 25076 - Epoch 52	 Loss_D =  0.6915	 Loss_G =  0.6974
2024-07-03 23:07:52,2053954106 | INFO | 25076 - Epoch 53	 Loss_D =  0.7467	 Loss_G =  0.6789
2024-07-03 23:07:52,2053954119 | INFO | 25076 - Epoch 54	 Loss_D =  0.6834	 Loss_G =  0.6948
2024-07-03 23:07:52,2053954134 | INFO | 25076 - Epoch 55	 Loss_D =  0.6305	 Loss_G =  0.6720
2024-07-03 23:07:52,2053954149 | INFO | 25076 - Epoch 56	 Loss_D =  0.6978	 Loss_G =  0.7284
2024-07-03 23:07:52,2053954163 | INFO | 25076 - Epoch 57	 Loss_D =  0.6144	 Loss_G =  0.6873
2024-07-03 23:07:52,2053954177 | INFO | 25076 - Epoch 58	 Loss_D =  0.6693	 Loss_G =  0.6756
2024-07-03 23:07:52,2053954193 | INFO | 25076 - Epoch 59	 Loss_D =  0.6994	 Loss_G =  0.6878
2024-07-03 23:07:52,2053954208 | INFO | 25076 - Epoch 60	 Loss_D =  0.6784	 Loss_G =  0.7001
2024-07-03 23:07:52,2053954223 | INFO | 25076 - Epoch 61	 Loss_D =  0.6800	 Loss_G =  0.7089
2024-07-03 23:07:52,2053954238 | INFO | 25076 - Epoch 62	 Loss_D =  0.6770	 Loss_G =  0.6881
2024-07-03 23:07:52,2053954253 | INFO | 25076 - Epoch 63	 Loss_D =  0.6432	 Loss_G =  0.7125
2024-07-03 23:07:52,2053954268 | INFO | 25076 - Epoch 64	 Loss_D =  0.7288	 Loss_G =  0.6759
2024-07-03 23:07:52,2053954283 | INFO | 25076 - Epoch 65	 Loss_D =  0.6546	 Loss_G =  0.7224
2024-07-03 23:07:52,2053954298 | INFO | 25076 - Epoch 66	 Loss_D =  0.7151	 Loss_G =  0.7080
2024-07-03 23:07:52,2053954313 | INFO | 25076 - Epoch 67	 Loss_D =  0.7331	 Loss_G =  0.8147
2024-07-03 23:07:52,2053954328 | INFO | 25076 - Epoch 68	 Loss_D =  0.6661	 Loss_G =  0.7218
2024-07-03 23:07:52,2053954345 | INFO | 25076 - Epoch 69	 Loss_D =  0.7720	 Loss_G =  0.6995
2024-07-03 23:07:52,2053954359 | INFO | 25076 - Epoch 70	 Loss_D =  0.5651	 Loss_G =  0.7023
2024-07-03 23:07:52,2053954374 | INFO | 25076 - Epoch 71	 Loss_D =  0.6791	 Loss_G =  0.7479
2024-07-03 23:07:52,2053954388 | INFO | 25076 - Epoch 72	 Loss_D =  0.7284	 Loss_G =  0.6641
2024-07-03 23:07:52,2053954402 | INFO | 25076 - Epoch 73	 Loss_D =  0.7349	 Loss_G =  0.6505
2024-07-03 23:07:52,2053954417 | INFO | 25076 - Epoch 74	 Loss_D =  0.6381	 Loss_G =  0.6541
2024-07-03 23:07:52,2053954432 | INFO | 25076 - Epoch 75	 Loss_D =  0.7164	 Loss_G =  0.6606
2024-07-03 23:07:52,2053954445 | INFO | 25076 - Epoch 76	 Loss_D =  0.6794	 Loss_G =  0.6515
2024-07-03 23:07:52,2053954459 | INFO | 25076 - Epoch 77	 Loss_D =  0.7313	 Loss_G =  0.6848
2024-07-03 23:07:52,2053954474 | INFO | 25076 - Epoch 78	 Loss_D =  0.6535	 Loss_G =  0.6654
2024-07-03 23:07:52,2053954488 | INFO | 25076 - Epoch 79	 Loss_D =  0.6801	 Loss_G =  0.6717
2024-07-03 23:07:52,2053954501 | INFO | 25076 - Epoch 80	 Loss_D =  0.7094	 Loss_G =  0.6298
2024-07-03 23:07:52,2053954515 | INFO | 25076 - Epoch 81	 Loss_D =  0.6925	 Loss_G =  0.6547
2024-07-03 23:07:52,2053954530 | INFO | 25076 - Epoch 82	 Loss_D =  0.7043	 Loss_G =  0.6478
2024-07-03 23:07:52,2053954544 | INFO | 25076 - Epoch 83	 Loss_D =  0.6698	 Loss_G =  0.6880
2024-07-03 23:07:52,2053954559 | INFO | 25076 - Epoch 84	 Loss_D =  0.6783	 Loss_G =  0.6561
2024-07-03 23:07:52,2053954573 | INFO | 25076 - Epoch 85	 Loss_D =  0.5904	 Loss_G =  0.6393
2024-07-03 23:07:52,2053954589 | INFO | 25076 - Epoch 86	 Loss_D =  0.6673	 Loss_G =  0.7253
2024-07-03 23:07:53,2053954605 | INFO | 25076 - Epoch 87	 Loss_D =  0.5830	 Loss_G =  0.6779
2024-07-03 23:07:53,2053954620 | INFO | 25076 - Epoch 88	 Loss_D =  0.7216	 Loss_G =  0.6636
2024-07-03 23:07:53,2053954634 | INFO | 25076 - Epoch 89	 Loss_D =  0.6538	 Loss_G =  0.6923
2024-07-03 23:07:53,2053954649 | INFO | 25076 - Epoch 90	 Loss_D =  0.6721	 Loss_G =  0.6939
2024-07-03 23:07:53,2053954663 | INFO | 25076 - Epoch 91	 Loss_D =  0.6562	 Loss_G =  0.6860
2024-07-03 23:07:53,2053954678 | INFO | 25076 - Epoch 92	 Loss_D =  0.6353	 Loss_G =  0.7653
2024-07-03 23:07:53,2053954693 | INFO | 25076 - Epoch 93	 Loss_D =  0.6678	 Loss_G =  0.7325
2024-07-03 23:07:53,2053954708 | INFO | 25076 - Epoch 94	 Loss_D =  0.5957	 Loss_G =  0.7722
2024-07-03 23:07:53,2053954723 | INFO | 25076 - Epoch 95	 Loss_D =  0.7626	 Loss_G =  0.7035
2024-07-03 23:07:53,2053954737 | INFO | 25076 - Epoch 96	 Loss_D =  0.6444	 Loss_G =  0.7145
2024-07-03 23:07:53,2053954751 | INFO | 25076 - Epoch 97	 Loss_D =  0.6828	 Loss_G =  0.7299
2024-07-03 23:07:53,2053954765 | INFO | 25076 - Epoch 98	 Loss_D =  0.6612	 Loss_G =  0.6943
2024-07-03 23:07:53,2053954779 | INFO | 25076 - Epoch 99	 Loss_D =  0.5940	 Loss_G =  0.7170
2024-07-03 23:07:53,2053955375 | INFO | 25076 - GAN trained on cpu in: 37.58696150779724 secs
2024-07-03 23:07:54,2053956222 | INFO | 25076 - Saved: GAN-2720a4c91b0a5f8cfef5a5a97fca8c4a
2024-07-03 23:07:54,2053956226 | INFO | 25076 - Instantiating: src.utils.samplers.partial_order_samplers.PositiveAndNegativeEdgeSampler
2024-07-03 23:07:57,2053958769 | INFO | 25076 - Creating: RSGG-113e7cfb03f0b6ac8c782e6cbd8f5a94
2024-07-03 23:07:57,2053958770 | INFO | 25076 - RSGG trained on cpu in: 0.0010073184967041016 secs
2024-07-03 23:07:57,2053958772 | INFO | 25076 - Saved: RSGG-113e7cfb03f0b6ac8c782e6cbd8f5a94
2024-07-03 23:07:57,2053958778 | INFO | 25076 - Created: RSGG-113e7cfb03f0b6ac8c782e6cbd8f5a94
2024-07-03 23:07:57,2053958779 | INFO | 25076 - Evaluating the explainers.............................................................
2024-07-03 23:12:41,2054243126 | INFO | 25076 - Evaluating instance with id 16
2024-07-03 23:12:41,2054243218 | INFO | 25076 - evaluated instance with id 16
2024-07-03 23:13:30,2054292460 | INFO | 25076 - Evaluating instance with id 1001
2024-07-03 23:13:30,2054292525 | INFO | 25076 - evaluated instance with id 1001
2024-07-03 23:14:32,2054354316 | INFO | 25076 - Evaluating instance with id 2001
2024-07-03 23:14:32,2054354399 | INFO | 25076 - evaluated instance with id 2001
2024-07-03 23:15:20,2054401606 | INFO | 25076 - Evaluating instance with id 3039
2024-07-03 23:15:20,2054401677 | INFO | 25076 - evaluated instance with id 3039
